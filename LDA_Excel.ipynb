{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PIrMhmXU-weUaTgHy59cE9OWsBuvzxvZ",
      "authorship_tag": "ABX9TyOxieD1hWOdKBYAkeagHMod",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albordunos/AI_literacy/blob/main/LDA_Excel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic modeling\n",
        "- это подход к анализу текстов, который позволяет автоматически выявлять скрытые темы в коллекции документов. Этот подход помогает исследователям обнаруживать основные темы, которые присутствуют в текстах, и группировать документы по этим темам.\n",
        "\n",
        "# Основные шаги для проведения topic modeling:\n",
        "\n",
        "## 1. Подготовка данных:\n",
        "Исследователи должны собрать и подготовить текстовую коллекцию для анализа. Это включает в себя очистку текста от шума, удаление стоп-слов и приведение текста к стандартному формату.\n",
        "\n"
      ],
      "metadata": {
        "id": "210n-Sp2GDss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sBZc7KtZHc_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Phrases  # Импортируем класс Phrases\n",
        "\n",
        "# Определение своих стоп-слов\n",
        "custom_stop_words = ['ai', 'intelligence', 'artificial', 'literacy', 'students', 'learning']\n",
        "\n",
        "# Очистка данных от стоп слов и токенизация\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english') + custom_stop_words)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        filtered_tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
        "        return filtered_tokens\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Загрузка данных из Excel файла\n",
        "file_path = '/content/AILIT_SHORT.xlsx'  #загрузить файл и прописать путь к нему\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Применение функции preprocess_text к столбцу 'Abstract'\n",
        "data['cleaned_abstract'] = data['Abstract'].apply(preprocess_text) #переименовать название столбца \"Abstracts\"\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Выбор модели:\n",
        "Для проведения topic modeling исследователи должны выбрать подходящую модель, такую как Latent Dirichlet Allocation (LDA) или Non-Negative Matrix Factorization (NMF). Каждая модель имеет свои особенности, и выбор модели зависит от конкретной задачи и структуры данных. Про сравнение моделей можно прочитать [тут](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9120935/).\n",
        "\n",
        "## 3. Обучение модели:\n",
        " После выбора модели исследователи должны обучить ее на текстовых данных. Обучение модели topic modeling включает в себя настройку параметров модели и определение числа тем, которые необходимо выделить.\n",
        "\n",
        "\n",
        "data['cleaned_abstract'] - это список текстовых данных, из которых будут извлекаться биграммы.\n",
        "\n",
        "min_count=5 означает, что биграммы, которые встречаются менее 5 раз во всем корпусе текстов, будут проигнорированы.\n",
        "\n",
        "threshold=10 - это порог ассоциации между словами в биграмме. Чем выше этот параметр, тем более \"связанными\" должны быть слова, чтобы образовывать биграмму.\n",
        "\n",
        "start = 2:\n",
        "Это начальное количество тем для проверки. Модель будет проверять от 2 тем и выше. Выбор 2 как начального значения позволяет избежать моделей с одной темой, которые обычно не дают полезной информации.\n",
        "\n",
        "limit = 10:\n",
        "Это максимальное количество тем, которое вы хотите проверить.\n",
        "В данном случае проверка будет проводиться до 10 тем.\n",
        "Это значение можно изменить в зависимости от объема данных и целей анализа. Например, если у вас много данных, вы можете увеличить это значение, чтобы исследовать большее количество тем.\n",
        "\n",
        "step = 1:\n",
        "Это шаг, с которым будет увеличиваться количество тем на каждой итерации.\n",
        "В данном случае шаг равен 1, что означает, что количество тем будет увеличиваться на 1 на каждой итерации (2, 3, 4, ..., 10)."
      ],
      "metadata": {
        "id": "jTn-qd9LGkq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание биграмм\n",
        "bigram_model = Phrases(data['cleaned_abstract'], min_count=5, threshold=10)\n",
        "data['bigrams'] = data['cleaned_abstract'].apply(lambda tokens: bigram_model[tokens])"
      ],
      "metadata": {
        "id": "cGhaWArnfxvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Создание словаря и корпуса\n",
        "dictionary = corpora.Dictionary(data['bigrams'])\n",
        "corpus = [dictionary.doc2bow(text) for text in data['bigrams']]\n",
        "\n",
        "# Вычисление TF-IDF\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "corpus_tfidf = tfidf[corpus]\n",
        "\n",
        "# Функция для вычисления когерентности, perplexity и log likelihood модели LDA\n",
        "def compute_metrics(dictionary, corpus, texts, limit=8, start=2, step=1):\n",
        "    coherence_values = []\n",
        "    perplexity_values = []\n",
        "    log_likelihood_values = []\n",
        "    model_list = []\n",
        "    num_topics_range = []\n",
        "\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=150)\n",
        "        model_list.append(model)\n",
        "\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "        perplexity_values.append(-model.log_perplexity(corpus))\n",
        "        log_likelihood_values.append(model.bound(corpus))\n",
        "\n",
        "        num_topics_range.append(num_topics)\n",
        "\n",
        "    return model_list, coherence_values, perplexity_values, log_likelihood_values, num_topics_range\n",
        "\n",
        "# Параметры для подбора количества тем\n",
        "start = 2\n",
        "limit = 6  # максимальное количество тем, которое вы хотите проверить\n",
        "step = 1\n",
        "\n",
        "if limit < start:\n",
        "    print(\"Ошибка: limit должно быть больше или равно start\")\n",
        "    exit()\n",
        "if step <= 0:\n",
        "    print(\"Ошибка: step должно быть больше 0\")\n",
        "    exit()\n",
        "\n",
        "# Вычисление метрик для различных значений num_topics\n",
        "model_list, coherence_values, perplexity_values, log_likelihood_values, num_topics_range = compute_metrics(dictionary, corpus_tfidf, data['bigrams'], limit, start, step)\n",
        "\n",
        "# Создание таблицы с результатами\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Num Topics': num_topics_range,\n",
        "    'Coherence': coherence_values,\n",
        "    'Perplexity': perplexity_values,\n",
        "    'Log Likelihood': log_likelihood_values\n",
        "})\n",
        "print(metrics_df)\n",
        "\n",
        "# Отображение результатов\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(num_topics_range, coherence_values)\n",
        "plt.xlabel(\"Количество тем\")\n",
        "plt.ylabel(\"Coherence\")\n",
        "plt.legend((\"Coherence\"), loc='best')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(num_topics_range, perplexity_values)\n",
        "plt.xlabel(\"Количество тем\")\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.legend((\"Perplexity\"), loc='best')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(num_topics_range, log_likelihood_values)\n",
        "plt.xlabel(\"Количество тем\")\n",
        "plt.ylabel(\"Log Likelihood\")\n",
        "plt.legend((\"Log Likelihood\"), loc='best')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Вывод количества тем с максимальной когерентностью\n",
        "optimal_num_topics = num_topics_range[coherence_values.index(max(coherence_values))]\n",
        "print(f'Оптимальное количество тем по когерентности: {optimal_num_topics}')\n",
        "\n",
        "# Вывод количества тем с максимальной perplexity\n",
        "optimal_num_topics_perplexity = num_topics_range[perplexity_values.index(max(perplexity_values))]\n",
        "print(f'Оптимальное количество тем по perplexity: {optimal_num_topics_perplexity}')\n",
        "\n",
        "# Вывод количества тем с максимальной log likelihood\n",
        "optimal_num_topics_log_likelihood = num_topics_range[log_likelihood_values.index(max(log_likelihood_values))]\n",
        "print(f'Оптимальное количество тем по log likelihood: {optimal_num_topics_log_likelihood}')"
      ],
      "metadata": {
        "id": "VX91gvIWf4IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import models\n",
        "\n",
        "\n",
        "# Параметры для подбора количества тем\n",
        "num_topics = int(input(\"Введите количество тем: \"))\n",
        "\n",
        "# Создание модели LDA с заданным количеством тем\n",
        "lda_model = models.LdaModel(corpus_tfidf, num_topics=num_topics, id2word=dictionary, passes=150)\n",
        "\n",
        "\n",
        "# Функция для получения доминирующей темы для документа\n",
        "def get_dominant_topic(lda_model, doc_topics):\n",
        "    return max(doc_topics, key=lambda item: item[1])\n",
        "\n",
        "# Получение тем для всех документов\n",
        "doc_topics = lda_model.get_document_topics(corpus_tfidf)\n",
        "\n",
        "# Вывод результатов\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {}'.format(idx))\n",
        "    print('Words: {}'.format(topic))\n",
        "\n",
        "    # Получение документов, относящихся к теме\n",
        "    doc_topics = lda_model.get_document_topics(corpus_tfidf)\n",
        "    docs = [doc_id for doc_id, topic_values in enumerate(doc_topics) if max(topic_values, key=lambda x: x[1])[0] == idx]\n",
        "\n",
        "    # Вывод номеров строк для темы\n",
        "    print('Документы (строки):', docs)\n",
        "    print()"
      ],
      "metadata": {
        "id": "m8lc9rCBGLEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Интерпретация результатов:\n",
        "\n",
        "После обучения модели исследователи могут проанализировать результаты topic modeling. Это включает в себя изучение выделенных тем, определение ключевых слов и документов, относящихся к каждой теме, а также оценку качества модели."
      ],
      "metadata": {
        "id": "-gOKbgruHNpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis\n"
      ],
      "metadata": {
        "id": "xAy-BzlIaXlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import LdaModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "# Создание визуализации\n",
        "vis_data = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(vis_data)\n",
        "\n",
        "# Создание визуализации для каждой темы отдельно\n",
        "vis_data = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary, mds='tsne')\n",
        "pyLDAvis.display(vis_data)"
      ],
      "metadata": {
        "id": "2ZeQpqmsbFeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Получение наиболее вероятных слов для каждой темы\n",
        "topics_words = lda_model.show_topics(formatted=False)\n",
        "\n",
        "# Создание облака слов для каждой темы\n",
        "for topic_id, topic in topics_words:\n",
        "    word_freq = {word: freq for word, freq in topic}\n",
        "\n",
        "    # Генерация облака слов\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
        "\n",
        "    # Визуализация облака слов\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Topic {topic_id}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yQVJAAj5bZre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}